{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5YF89xwC9USI",
        "outputId": "4be8b7ef-c6c8-4bf4-c3e9-eb4f3bd4169f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2026-01-30 10:49:05--  https://raw.githubusercontent.com/karpathy/char-rnn/master/data/tinyshakespeare/input.txt\n",
            "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 185.199.108.133, 185.199.109.133, 185.199.110.133, ...\n",
            "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|185.199.108.133|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 1115394 (1.1M) [text/plain]\n",
            "Saving to: ‘input.txt’\n",
            "\n",
            "input.txt           100%[===================>]   1.06M  --.-KB/s    in 0.01s   \n",
            "\n",
            "2026-01-30 10:49:05 (105 MB/s) - ‘input.txt’ saved [1115394/1115394]\n",
            "\n"
          ]
        }
      ],
      "source": [
        "!wget https://raw.githubusercontent.com/karpathy/char-rnn/master/data/tinyshakespeare/input.txt"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "with open('input.txt','r',encoding = 'UTF-8') as f:\n",
        "  text = f.read()"
      ],
      "metadata": {
        "id": "Xg4-6tN19i9_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "len(text)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0odhbQCF93P9",
        "outputId": "4801ffd7-1b05-4783-a18a-de7b2f36debd"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "1115394"
            ]
          },
          "metadata": {},
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "chars = sorted(list(set(text)))\n",
        "vocab_size = 65"
      ],
      "metadata": {
        "id": "u9TtaZ7396cx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "stoi = { ch:i for i,ch in enumerate(chars) }\n",
        "itos = { i:ch for i,ch in enumerate(chars) }\n",
        "encode = lambda s: [stoi[c] for c in s] # encoder: take a string, output a list of integers\n",
        "decode = lambda l: ''.join([itos[i] for i in l]) # decoder: take a list of integers, output a string\n",
        "\n",
        "print(encode(\"hii there\"))\n",
        "print(decode(encode(\"hii there\")))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UB7IVh6a-GP7",
        "outputId": "7ed34a1f-df93-4b5b-fb85-072f55e09d52"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[46, 47, 47, 1, 58, 46, 43, 56, 43]\n",
            "hii there\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch # we use PyTorch: https://pytorch.org\n",
        "data = torch.tensor(encode(text), dtype=torch.long)\n",
        "print(data.shape, data.dtype)\n",
        "print(data[:1000])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "XECRAvO0-I9n",
        "outputId": "510d4e47-e955-4a0b-f722-252acabe17d9"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([1115394]) torch.int64\n",
            "tensor([18, 47, 56, 57, 58,  1, 15, 47, 58, 47, 64, 43, 52, 10,  0, 14, 43, 44,\n",
            "        53, 56, 43,  1, 61, 43,  1, 54, 56, 53, 41, 43, 43, 42,  1, 39, 52, 63,\n",
            "         1, 44, 59, 56, 58, 46, 43, 56,  6,  1, 46, 43, 39, 56,  1, 51, 43,  1,\n",
            "        57, 54, 43, 39, 49,  8,  0,  0, 13, 50, 50, 10,  0, 31, 54, 43, 39, 49,\n",
            "         6,  1, 57, 54, 43, 39, 49,  8,  0,  0, 18, 47, 56, 57, 58,  1, 15, 47,\n",
            "        58, 47, 64, 43, 52, 10,  0, 37, 53, 59,  1, 39, 56, 43,  1, 39, 50, 50,\n",
            "         1, 56, 43, 57, 53, 50, 60, 43, 42,  1, 56, 39, 58, 46, 43, 56,  1, 58,\n",
            "        53,  1, 42, 47, 43,  1, 58, 46, 39, 52,  1, 58, 53,  1, 44, 39, 51, 47,\n",
            "        57, 46, 12,  0,  0, 13, 50, 50, 10,  0, 30, 43, 57, 53, 50, 60, 43, 42,\n",
            "         8,  1, 56, 43, 57, 53, 50, 60, 43, 42,  8,  0,  0, 18, 47, 56, 57, 58,\n",
            "         1, 15, 47, 58, 47, 64, 43, 52, 10,  0, 18, 47, 56, 57, 58,  6,  1, 63,\n",
            "        53, 59,  1, 49, 52, 53, 61,  1, 15, 39, 47, 59, 57,  1, 25, 39, 56, 41,\n",
            "        47, 59, 57,  1, 47, 57,  1, 41, 46, 47, 43, 44,  1, 43, 52, 43, 51, 63,\n",
            "         1, 58, 53,  1, 58, 46, 43,  1, 54, 43, 53, 54, 50, 43,  8,  0,  0, 13,\n",
            "        50, 50, 10,  0, 35, 43,  1, 49, 52, 53, 61,  5, 58,  6,  1, 61, 43,  1,\n",
            "        49, 52, 53, 61,  5, 58,  8,  0,  0, 18, 47, 56, 57, 58,  1, 15, 47, 58,\n",
            "        47, 64, 43, 52, 10,  0, 24, 43, 58,  1, 59, 57,  1, 49, 47, 50, 50,  1,\n",
            "        46, 47, 51,  6,  1, 39, 52, 42,  1, 61, 43,  5, 50, 50,  1, 46, 39, 60,\n",
            "        43,  1, 41, 53, 56, 52,  1, 39, 58,  1, 53, 59, 56,  1, 53, 61, 52,  1,\n",
            "        54, 56, 47, 41, 43,  8,  0, 21, 57,  5, 58,  1, 39,  1, 60, 43, 56, 42,\n",
            "        47, 41, 58, 12,  0,  0, 13, 50, 50, 10,  0, 26, 53,  1, 51, 53, 56, 43,\n",
            "         1, 58, 39, 50, 49, 47, 52, 45,  1, 53, 52,  5, 58, 11,  1, 50, 43, 58,\n",
            "         1, 47, 58,  1, 40, 43,  1, 42, 53, 52, 43, 10,  1, 39, 61, 39, 63,  6,\n",
            "         1, 39, 61, 39, 63,  2,  0,  0, 31, 43, 41, 53, 52, 42,  1, 15, 47, 58,\n",
            "        47, 64, 43, 52, 10,  0, 27, 52, 43,  1, 61, 53, 56, 42,  6,  1, 45, 53,\n",
            "        53, 42,  1, 41, 47, 58, 47, 64, 43, 52, 57,  8,  0,  0, 18, 47, 56, 57,\n",
            "        58,  1, 15, 47, 58, 47, 64, 43, 52, 10,  0, 35, 43,  1, 39, 56, 43,  1,\n",
            "        39, 41, 41, 53, 59, 52, 58, 43, 42,  1, 54, 53, 53, 56,  1, 41, 47, 58,\n",
            "        47, 64, 43, 52, 57,  6,  1, 58, 46, 43,  1, 54, 39, 58, 56, 47, 41, 47,\n",
            "        39, 52, 57,  1, 45, 53, 53, 42,  8,  0, 35, 46, 39, 58,  1, 39, 59, 58,\n",
            "        46, 53, 56, 47, 58, 63,  1, 57, 59, 56, 44, 43, 47, 58, 57,  1, 53, 52,\n",
            "         1, 61, 53, 59, 50, 42,  1, 56, 43, 50, 47, 43, 60, 43,  1, 59, 57, 10,\n",
            "         1, 47, 44,  1, 58, 46, 43, 63,  0, 61, 53, 59, 50, 42,  1, 63, 47, 43,\n",
            "        50, 42,  1, 59, 57,  1, 40, 59, 58,  1, 58, 46, 43,  1, 57, 59, 54, 43,\n",
            "        56, 44, 50, 59, 47, 58, 63,  6,  1, 61, 46, 47, 50, 43,  1, 47, 58,  1,\n",
            "        61, 43, 56, 43,  0, 61, 46, 53, 50, 43, 57, 53, 51, 43,  6,  1, 61, 43,\n",
            "         1, 51, 47, 45, 46, 58,  1, 45, 59, 43, 57, 57,  1, 58, 46, 43, 63,  1,\n",
            "        56, 43, 50, 47, 43, 60, 43, 42,  1, 59, 57,  1, 46, 59, 51, 39, 52, 43,\n",
            "        50, 63, 11,  0, 40, 59, 58,  1, 58, 46, 43, 63,  1, 58, 46, 47, 52, 49,\n",
            "         1, 61, 43,  1, 39, 56, 43,  1, 58, 53, 53,  1, 42, 43, 39, 56, 10,  1,\n",
            "        58, 46, 43,  1, 50, 43, 39, 52, 52, 43, 57, 57,  1, 58, 46, 39, 58,  0,\n",
            "        39, 44, 44, 50, 47, 41, 58, 57,  1, 59, 57,  6,  1, 58, 46, 43,  1, 53,\n",
            "        40, 48, 43, 41, 58,  1, 53, 44,  1, 53, 59, 56,  1, 51, 47, 57, 43, 56,\n",
            "        63,  6,  1, 47, 57,  1, 39, 57,  1, 39, 52,  0, 47, 52, 60, 43, 52, 58,\n",
            "        53, 56, 63,  1, 58, 53,  1, 54, 39, 56, 58, 47, 41, 59, 50, 39, 56, 47,\n",
            "        57, 43,  1, 58, 46, 43, 47, 56,  1, 39, 40, 59, 52, 42, 39, 52, 41, 43,\n",
            "        11,  1, 53, 59, 56,  0, 57, 59, 44, 44, 43, 56, 39, 52, 41, 43,  1, 47,\n",
            "        57,  1, 39,  1, 45, 39, 47, 52,  1, 58, 53,  1, 58, 46, 43, 51,  1, 24,\n",
            "        43, 58,  1, 59, 57,  1, 56, 43, 60, 43, 52, 45, 43,  1, 58, 46, 47, 57,\n",
            "         1, 61, 47, 58, 46,  0, 53, 59, 56,  1, 54, 47, 49, 43, 57,  6,  1, 43,\n",
            "        56, 43,  1, 61, 43,  1, 40, 43, 41, 53, 51, 43,  1, 56, 39, 49, 43, 57,\n",
            "        10,  1, 44, 53, 56,  1, 58, 46, 43,  1, 45, 53, 42, 57,  1, 49, 52, 53,\n",
            "        61,  1, 21,  0, 57, 54, 43, 39, 49,  1, 58, 46, 47, 57,  1, 47, 52,  1,\n",
            "        46, 59, 52, 45, 43, 56,  1, 44, 53, 56,  1, 40, 56, 43, 39, 42,  6,  1,\n",
            "        52, 53, 58,  1, 47, 52,  1, 58, 46, 47, 56, 57, 58,  1, 44, 53, 56,  1,\n",
            "        56, 43, 60, 43, 52, 45, 43,  8,  0,  0])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "n = int(0.9*len(data))"
      ],
      "metadata": {
        "id": "GeIWkW76-L1Q"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_data = data[:n]\n",
        "test_data = data[n:]"
      ],
      "metadata": {
        "id": "7uYqMxkz-THA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "\n",
        "batch_size = 16\n",
        "block_size = 32\n",
        "max_iters = 5000\n",
        "eval_interval = 100\n",
        "learning_rate = 1e-3\n",
        "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
        "n_embd = 64\n",
        "n_head = 4\n",
        "n_layer = 4\n",
        "dropout = 0.0\n",
        "eval_iters = 200\n",
        "\n",
        "\n",
        "def get_batch(split):\n",
        "\n",
        "  data = train_data if split == 'train' else test_data\n",
        "  ix = torch.randint(len(data)-block_size, (batch_size,))\n",
        "  x = torch.stack([data[i:i+block_size] for i in ix])\n",
        "  y = torch.stack([data[i+1:i+1+block_size] for i in ix])\n",
        "\n",
        "  x, y = x.to(device), y.to(device)\n",
        "\n",
        "  return x, y\n",
        "\n",
        "\n",
        "\n",
        "@torch.no_grad()\n",
        "def estimate_loss():\n",
        "  out = {}\n",
        "  model.eval()\n",
        "  for split in ['train','test']:\n",
        "    losses = torch.zeros(eval_iters)\n",
        "    for k in range(eval_iters):\n",
        "      X, Y = get_batch(split)\n",
        "      logits, loss = model(X, Y)\n",
        "      losses[k] = loss.item()\n",
        "    out[split] = losses.mean()\n",
        "  model.train()\n",
        "  return out\n",
        "\n",
        "\n",
        "class Head(nn.Module):\n",
        "  # only 1 head of attention\n",
        "\n",
        "  def __init__(self, head_size):\n",
        "    super().__init__()\n",
        "    self.key = nn.Linear(n_embd, head_size, bias=False)\n",
        "    self.query = nn.Linear(n_embd, head_size, bias = False)\n",
        "    self.value = nn.Linear(n_embd, head_size, bias = False)\n",
        "    self.register_buffer('tril', torch.tril(torch.ones(block_size, block_size)))\n",
        "    self.dropout = nn.Dropout(dropout)\n",
        "\n",
        "  def forward(self,x):\n",
        "\n",
        "    B,T,C = x.shape\n",
        "    k = self.key(x)   #(B,T,C)\n",
        "    q = self.query(x)  #(B,T,C)\n",
        "\n",
        "    wei = q @ k.transpose(-2,-1)*C**-0.5   #(B,T,C) x (B,T,C) => k->(B,T,C)->(B,C,T) => wei=(B,T,C)\n",
        "    wei = wei.masked_fill(self.tril[:T,:T]==0, float('-inf'))\n",
        "    wei = F.softmax(wei, dim = -1)\n",
        "    wei = self.dropout(wei)\n",
        "\n",
        "    v = self.value(x)\n",
        "    out = wei @ v    # (B, T, T) @ (B, T, C) -> (B, T, C)\n",
        "    return out\n",
        "\n",
        "class MultiHeadAttention(nn.Module):\n",
        "\n",
        "  def __init__(self, num_heads, head_size):\n",
        "    super().__init__()\n",
        "    self.heads = nn.ModuleList(Head(head_size) for _ in range(num_heads))\n",
        "    self.proj = nn.Linear(n_embd, n_embd)\n",
        "    self.dropout = nn.Dropout(dropout)\n",
        "\n",
        "  def forward(self, x):\n",
        "    out = torch.cat([h(x) for h in self.heads], dim = -1)\n",
        "    out = self.dropout(self.proj(out))\n",
        "    return out\n",
        "\n",
        "\n",
        "class FeedForward(nn.Module):\n",
        "\n",
        "  def __init__(self, n_embd):\n",
        "    super().__init__()\n",
        "    self.net = nn.Sequential(\n",
        "        nn.Linear(n_embd, 4*n_embd),\n",
        "        nn.ReLU(),\n",
        "        nn.Linear(4*n_embd, n_embd),\n",
        "        nn.Dropout(dropout)\n",
        "        )\n",
        "\n",
        "  def forward(self, x):\n",
        "    return self.net(x)\n",
        "\n",
        "class Block(nn.Module):\n",
        "\n",
        "    def __init__(self, n_embd, n_head):\n",
        "\n",
        "      super().__init__()\n",
        "      head_size = n_embd // n_head\n",
        "      self.sa = MultiHeadAttention(n_head, head_size)\n",
        "      self.ffwd = FeedForward(n_embd)\n",
        "      self.ln1 = nn.LayerNorm(n_embd)\n",
        "      self.ln2 = nn.LayerNorm(n_embd)\n",
        "\n",
        "    def forward(self, x):\n",
        "      x = x + self.sa(self.ln1(x))\n",
        "      x = x + self.ffwd(self.ln2(x))\n",
        "      return x\n",
        "\n",
        "class BiGramLanguageModel(nn.Module):\n",
        "\n",
        "  def __init__(self):\n",
        "    super().__init__()\n",
        "    self.token_embedding_table = nn.Embedding(vocab_size, n_embd)\n",
        "    self.position_embedding_table = nn.Embedding(block_size, n_embd)\n",
        "    self.blocks = nn.Sequential(*[Block(n_embd, n_head=n_head) for _ in range(n_layer)])\n",
        "    self.ln_f = nn.LayerNorm(n_embd)\n",
        "    self.lm_head = nn.Linear(n_embd, vocab_size)\n",
        "\n",
        "  def forward(self, idx, targets=None):\n",
        "    B, T = idx.shape\n",
        "\n",
        "    tok_emb = self.token_embedding_table(idx)\n",
        "    pos_emb = self.position_embedding_table(torch.arange(T, device=device))\n",
        "    x = tok_emb + pos_emb\n",
        "    x = self.blocks(x)\n",
        "    x = self.ln_f(x)\n",
        "    logits = self.lm_head(x)\n",
        "\n",
        "    if targets is None:\n",
        "      loss = None\n",
        "    else:\n",
        "      B, T, C = logits.shape\n",
        "      logits = logits.view(B*T, C)\n",
        "      targets = targets.view(B*T)\n",
        "      loss = F.cross_entropy(logits, targets)\n",
        "\n",
        "    return logits, loss\n",
        "\n",
        "  def generate(self, idx, max_new_tokens):\n",
        "\n",
        "    for _ in range(max_new_tokens):\n",
        "\n",
        "      idx_cond = idx[:,-block_size:]\n",
        "\n",
        "      logits, loss = self(idx_cond)\n",
        "\n",
        "      logits = logits[:, -1, :]\n",
        "\n",
        "      probs = F.softmax(logits, dim = -1)\n",
        "\n",
        "      idx_next = torch.multinomial(probs, num_samples = 1)\n",
        "\n",
        "      idx = torch.cat((idx, idx_next), dim = 1)\n",
        "\n",
        "    return idx"
      ],
      "metadata": {
        "id": "HNBPN7aQ-Xkz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = BiGramLanguageModel()\n",
        "m = model.to(device)\n",
        "\n",
        "print(sum(p.numel() for p in m.parameters())/1e6, 'M parameters')\n",
        "\n",
        "optimizer = torch.optim.AdamW(model.parameters(), lr = learning_rate)\n",
        "\n",
        "\n",
        "for iter in range(max_iters):\n",
        "\n",
        "  if iter % eval_iters == 0 or iter == max_iters - 1:\n",
        "    losses = estimate_loss()\n",
        "    print(f\"step {iter}: train loss {losses['train']:.4f}, val loss {losses['test']:.4f}\")\n",
        "\n",
        "  xb, yb = get_batch('train')\n",
        "\n",
        "  logits,loss = model(xb, yb)\n",
        "  optimizer.zero_grad()\n",
        "  loss.backward()\n",
        "  optimizer.step()\n",
        "\n",
        "context = torch.zeros((1,1), dtype = torch.long, device = device)\n",
        "\n",
        "print(decode(m.generate(context, max_new_tokens = 2000)[0].tolist()))"
      ],
      "metadata": {
        "id": "wmkPIDnqFstF",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "876e73d8-3a63-4cad-ec52-829d12e884cb"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0.209729 M parameters\n",
            "step 0: train loss 4.3129, val loss 4.3161\n",
            "step 200: train loss 2.5064, val loss 2.5187\n",
            "step 400: train loss 2.3650, val loss 2.3702\n",
            "step 600: train loss 2.2690, val loss 2.2764\n",
            "step 800: train loss 2.1756, val loss 2.1988\n",
            "step 1000: train loss 2.0997, val loss 2.1373\n",
            "step 1200: train loss 2.0424, val loss 2.0919\n",
            "step 1400: train loss 2.0071, val loss 2.0729\n",
            "step 1600: train loss 1.9594, val loss 2.0451\n",
            "step 1800: train loss 1.9181, val loss 2.0043\n",
            "step 2000: train loss 1.9053, val loss 1.9999\n",
            "step 2200: train loss 1.8669, val loss 1.9711\n",
            "step 2400: train loss 1.8435, val loss 1.9572\n",
            "step 2600: train loss 1.8218, val loss 1.9528\n",
            "step 2800: train loss 1.8108, val loss 1.9373\n",
            "step 3000: train loss 1.7912, val loss 1.9161\n",
            "step 3200: train loss 1.7619, val loss 1.9004\n",
            "step 3400: train loss 1.7552, val loss 1.8947\n",
            "step 3600: train loss 1.7523, val loss 1.8991\n",
            "step 3800: train loss 1.7322, val loss 1.8778\n",
            "step 4000: train loss 1.7084, val loss 1.8537\n",
            "step 4200: train loss 1.7038, val loss 1.8465\n",
            "step 4400: train loss 1.6889, val loss 1.8485\n",
            "step 4600: train loss 1.6833, val loss 1.8222\n",
            "step 4800: train loss 1.6685, val loss 1.8296\n",
            "step 4999: train loss 1.6580, val loss 1.8439\n",
            "\n",
            "\n",
            "\n",
            "KING RICHANLE:\n",
            "Nay, stands you, faimol set furment thyse,\n",
            "Our wrounce of the have sir?\n",
            "\n",
            "Nurse:\n",
            "A what'd for Lend I thou have their wuse\n",
            "Spent the leave head's king, of from itter me:\n",
            "And what them.\n",
            "\n",
            "GLOUCESTER:\n",
            "HAStry, the have your gold the that ubjenton;\n",
            "And at a suay! Clarently chears?\n",
            "\n",
            "QUEEN MARGARET:\n",
            "Lord:\n",
            "Thou is will theses! Cliftly repongs.\n",
            "Beauther is, set deepher; if a should glive fliss on strenging,\n",
            "And Elimently, foollow them, of father?\n",
            "What take me turn this oun the breot them bring That Bringed of death, his good chidle your the oldly done!\n",
            "\n",
            "SICK:\n",
            "Dow the kingdy, ringblle Edward I maje his squaked my sould mark states then with them hee awas.\n",
            "\n",
            "MENENIUS:\n",
            "Boseantanish your bestlestr: years\n",
            "Shall are sorta's of my cainst and heart\n",
            "e lounces eving.\n",
            "\n",
            "KE RIGHHARD:\n",
            "From your therefore grave shoulve viond heart it fasbaek youll.\n",
            "\n",
            "FurthfUricengb'd been of Maden, as blensue person.\n",
            "\n",
            "Pomen:\n",
            "Sto away, stomer of master.\n",
            "\n",
            "Second as that down my direath the merrent Walousraced maeve be his bescoudiciausecy,\n",
            "Upon these is As kings that be you\n",
            "gr him and exouse ever\n",
            "When saull mest'd sarr.\n",
            "\n",
            "KING RICHARD:\n",
            "Here at your what sust now gir.\n",
            "st all be their for against true;\n",
            "Besing of yield, seveign for uph slay me\n",
            "To met for your bosel's apput himsing from these for 'wof from when should of,\n",
            "'Can you grands us you fatherity. I will dam? Mystlathes not thou krate out scature;\n",
            "You which go? that grief let I chass thouse's sounly their be thou liveds?\n",
            "\n",
            "GRIAND:\n",
            "Gneelss sisir, them, durn in himes weat te desom.\n",
            "\n",
            "LADY ANGSTER:\n",
            "But thee? us, as he own furse haven the\n",
            "chirds to them; assaw that, now should the ach my failsy mink sight.\n",
            "\n",
            "First Thou OF AULEd Onest; there's mise or bealy himselves:\n",
            "They and me, must the had doresbst hepe?\n",
            "What I held at the him brokes to as will my cause intast.\n",
            "\n",
            "Nry, BENuch Edwards,\n",
            "Peases, thou luve thee curdius, thou sofflet of Comen themsel armer plehert pirt his pick'd bearing are curse on infender trighter clail dist.\n",
            "\n",
            "KING EDWARD III:\n",
            "The s\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(decode(m.generate(context, max_new_tokens = 2000)[0].tolist()))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TkebR61ggsUV",
        "outputId": "23a794f4-d12b-49a0-e31a-e3cc87050b52"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Thou sumpeo desoneds or earshict thy while him hearts Onober,\n",
            "Why fair Solty'll themself heaven:\n",
            "I chink doth's see extry of Clorives to rigns?\n",
            "\n",
            "Nor go will now sir make: your pentaking exse.\n",
            "Titrance sore of not lot; King How thus on Cloinslain; did thy brinkes-- Isberned their any than messe\n",
            "That which is regnives! whoulss not, come as sinces! scarrtune.\n",
            "\n",
            "POLIxET:\n",
            "\n",
            "ANGELO:\n",
            "Prines shall Moman of them ben sir,' be my reash I satten's thou not shall fays.\n",
            "\n",
            "EXENIUS:\n",
            "Lord body trief: Myself. Mark'd, you when stralttence spery.\n",
            "! First,--\n",
            "Or bookingeloss, enentinging Lord him their pass!\n",
            "\n",
            "RICKINGHARD:\n",
            "What shall I sking to the fatom;\n",
            "As that is no sonle dutten her shall bedate\n",
            "Whet of my starge our vealione, death himsel\n",
            "With O say, she kears nowerw'st he tates,\n",
            "Which not made, if the persentedge thou him nor rewititness of Nisment.\n",
            "\n",
            "LEONTEGSS That my tone:\n",
            "Thou dekiss be ot marry.\n",
            "\n",
            "ISABELLA:\n",
            "A repence a pardons of Mower'd?\n",
            "\n",
            "RUMENEENIS:\n",
            "To the womblesan are us I tou, so, my in this went thy lovely, dise when that they statch.\n",
            "The, he sir, ishell'd out up. I'll would are them thee\n",
            "Where, now my flestly no sate and thy urbled\n",
            "As no lady the long himself your God fair?\n",
            "\n",
            "POLIXENE:\n",
            "This, not he chills\n",
            "Come singess dury love dear Long some men then my lord?\n",
            "Lord'd make him? Sir, for forth veepion wars fill.\n",
            "\n",
            "Nour ELmarY:\n",
            "And loo; Baithm'shour awn.\n",
            "\n",
            "ESCALUS:\n",
            "Who seel hose cause bland, and them is the pocleit,\n",
            "But state with their hearts me childry,\n",
            "I sad see, here day tell our genting you\n",
            "Stan, then Dimen can unto thy see in outh,\n",
            "That fair aule thy was sorre, sir; ah come:\n",
            "Thet hat lippect him sprince, she souls,\n",
            "As swicgold given dain the dreathne,\n",
            "Or crain's peat, awx that thee, yet\n",
            "With love 'Twon sound thy all our more?\n",
            "\n",
            "MENENIUSA:\n",
            "Hid them Filen, Many.\n",
            "\n",
            "Secondingmentend, tonguens of think 'I dearst's of an tulluck,\n",
            "My thou it, in be should request the beforience us in and was corx, and ollour'd, comes come,\n",
            "I'llse thee, wouth him an slay place at been must my?\n",
            "Wherell fi\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "QKJ5M84eih9j"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}